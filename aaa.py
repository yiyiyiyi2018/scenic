import streamlit as st
import sys
import pathlib
import os
import pickle
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from difflib import get_close_matches
from fastai.vision.all import load_learner, PILImage

# ------------------ Streamlit é¡µé¢é…ç½® ------------------
st.set_page_config(page_title="ç»¼åˆæ™¯ç‚¹æ¨èç³»ç»Ÿ", layout="wide")

# ------------------ Python ç‰ˆæœ¬æ£€æŸ¥ ------------------
if sys.version_info >= (3, 13):
    st.error("âš ï¸ å½“å‰ Python ç‰ˆæœ¬ä¸º 3.13+ï¼Œå¯èƒ½ä¸ fastai ä¸å…¼å®¹ã€‚å»ºè®®ä½¿ç”¨ Python 3.11ã€‚")
    st.stop()

# ------------------ Windows è·¯å¾„å…¼å®¹ ------------------
if sys.platform == "win32":
    pathlib.PosixPath = pathlib.WindowsPath

# ------------------ æ¨¡å‹ä¸æ•°æ®åŠ è½½å‡½æ•° ------------------
@st.cache_resource
def load_content_model():
    path = pathlib.Path(__file__).parent / "scenic_model.pkl"
    with open(path, "rb") as f:
        return pickle.load(f)

@st.cache_data
def load_feature_data():
    excel = pd.ExcelFile('æ™¯ç‚¹è¡¨.xlsx')
    df = excel.parse('Sheet1')
    return df

@st.cache_data
def load_scenic_info():
    df = pd.read_excel('æ™¯ç‚¹è¡¨ï¼ˆæ–°ï¼‰.xlsx', dtype={'æ™¯ç‚¹id': int})
    df = df.rename(columns={
        'æ™¯ç‚¹id': 'scenic_id',
        'æ™¯ç‚¹åç§°': 'scenic_name',
        'æ™¯ç‚¹ç®€ä»‹': 'scenic_introduction',
        'æ™¯ç‚¹åœ°å€': 'scenic_address'
    })[['scenic_id', 'scenic_name', 'scenic_introduction', 'scenic_address']]

    def imgs(r):
        folder = os.path.join('å›¾ç‰‡', r.scenic_name)
        if os.path.exists(folder):
            return [os.path.join(folder, f) for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))][:3]
        return []
    
    df['image_paths'] = df.apply(imgs, axis=1)
    return df

@st.cache_resource
def load_cls_model():
    temp = None
    if sys.platform == "win32":
        temp = pathlib.PosixPath
        pathlib.PosixPath = pathlib.WindowsPath
    try:
        model_path = pathlib.Path(__file__).parent / "é£æ™¯.pkl"
        model = load_learner(model_path)
    except Exception as e:
        st.error(f"åŠ è½½åˆ†ç±»æ¨¡å‹å¤±è´¥: {e}")
        st.stop()
    finally:
        if sys.platform == "win32" and temp is not None:
            pathlib.PosixPath = temp
    return model

# ------------------ å†…å®¹è¿‡æ»¤æ•°æ®å‡†å¤‡ ------------------
model_data = load_content_model()
df_feat = load_feature_data()

if isinstance(model_data, dict):
    if 'æ™¯ç‚¹_id' in model_data and 'feature_vector' in model_data and 'feature_list' in model_data:
        scenic_ids = model_data['æ™¯ç‚¹_id']
        feature_vectors = np.array(model_data['feature_vector'])
        feature_lists = model_data['feature_list']
    else:
        scenic_ids = model_data.get('scenic_ids', df_feat['æ™¯ç‚¹id'].tolist())
        feature_vectors = np.array(
            model_data.get('feature_vectors', df_feat.drop(columns=['æ™¯ç‚¹id', 'æ™¯ç‚¹åç§°', 'ç®€ä»‹', 'åœ°ç†ä½ç½®']).to_numpy())
        )
        names = df_feat.drop(columns=['æ™¯ç‚¹id', 'æ™¯ç‚¹åç§°', 'ç®€ä»‹', 'åœ°ç†ä½ç½®']).columns.tolist()
        feature_lists = [[names[i] for i, val in enumerate(row) if val == 1] for row in feature_vectors]
else:
    scenic_ids = df_feat['æ™¯ç‚¹id'].tolist()
    feature_vectors = df_feat.drop(columns=['æ™¯ç‚¹id', 'æ™¯ç‚¹åç§°', 'ç®€ä»‹', 'åœ°ç†ä½ç½®']).to_numpy()
    names = df_feat.drop(columns=['æ™¯ç‚¹id', 'æ™¯ç‚¹åç§°', 'ç®€ä»‹', 'åœ°ç†ä½ç½®']).columns.tolist()
    feature_lists = [[names[i] for i, val in enumerate(row) if val == 1] for row in feature_vectors]

all_features = sorted({f for feats in feature_lists for f in feats})

@st.cache_data
def calculate_similarity():
    if feature_vectors.size == 0 or feature_vectors.shape[1] == 0:
        return np.array([])
    norm = np.linalg.norm(feature_vectors, axis=1)
    if np.all(norm > 0):
        vecs = feature_vectors / norm[:, None]
        return cosine_similarity(vecs)
    return cosine_similarity(feature_vectors)

similarity_matrix = calculate_similarity()
scenic_id_to_idx = {sid: i for i, sid in enumerate(scenic_ids)}
scenic_name_to_id = {row['æ™¯ç‚¹åç§°']: row['æ™¯ç‚¹id'] for _, row in df_feat.iterrows()}

# ------------------ å·¥å…·å‡½æ•° ------------------
def recognize_images(files, model):
    results = []
    for f in files:
        image = PILImage.create(f)
        pred, pred_idx, probs = model.predict(image)
        results.append((str(pred), probs[pred_idx].item()))
    return results

def fuzzy_match(name, names):
    m = get_close_matches(name, names, n=1, cutoff=0.6)
    return m[0] if m else name

# ------------------ é¡µé¢é€»è¾‘ ------------------
def page_select():
    st.header("ğŸ“· ä¸Šä¼ ä¸‰å¼ æ™¯ç‚¹ç…§ç‰‡è¿›è¡Œè¯†åˆ«")
    files = st.file_uploader("ä¸Šä¼ ä¸‰å¼ å›¾ç‰‡", accept_multiple_files=True, type=['jpg', 'jpeg', 'png'])

    if files:
        if len(files) < 3:
            st.error("âš ï¸ è¯·ä¸Šä¼ è‡³å°‘ä¸‰å¼ å›¾ç‰‡ã€‚")
            st.stop()

        model = load_cls_model()
        preds = recognize_images(files, model)
        df_info = load_scenic_info()

        st.subheader("ğŸ” è¯†åˆ«ç»“æœä¸æ¨èæ™¯ç‚¹ï¼š")
        cols = st.columns(3)
        for i, (pred_name, pred_score) in enumerate(preds):
            matched_name = fuzzy_match(pred_name, df_info['scenic_name'].tolist())
            row = df_info[df_info['scenic_name'] == matched_name]

            with cols[i]:
                st.image(files[i], caption=f"ä¸Šä¼ å›¾ {i+1}", use_container_width=True)
                if not row.empty:
                    scenic = row.iloc[0]
                    st.markdown(f"**é¢„æµ‹ç»“æœï¼š{scenic['scenic_name']}**")
                    st.markdown(f"ğŸ“ˆ å‡†ç¡®ç‡: `{pred_score:.2%}`")
                    st.markdown(f"ğŸ—ºï¸ åœ°å€: {scenic['scenic_address']}")
                    st.markdown(f"ğŸ“– ç®€ä»‹: {scenic['scenic_introduction'][:100]}...")
                    for img in scenic['image_paths']:
                        st.image(img, width=120)
                else:
                    st.warning(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„æ™¯ç‚¹: `{pred_name}`")
    else:
        st.info("è¯·ä¸Šä¼ ä¸‰å¼ å›¾ç‰‡ã€‚")

def page_content_single():
    st.header("ğŸ¯ å†…å®¹è¿‡æ»¤ï¼šåŸºäºå•ä¸ªæ™¯ç‚¹æ¨è")
    selected = st.selectbox("é€‰æ‹©ä¸€ä¸ªæ™¯ç‚¹ï¼š", df_feat['æ™¯ç‚¹åç§°'].tolist())
    if selected and similarity_matrix.size:
        sid = scenic_name_to_id.get(selected)
        idx = scenic_id_to_idx.get(sid)
        if idx is not None:
            sims = similarity_matrix[idx].argsort()[::-1][1:11]
            for i, j in enumerate(sims):
                info = df_feat.iloc[j]
                score = similarity_matrix[idx][j]
                st.markdown(f"{i+1}. {info['æ™¯ç‚¹åç§°']} (ç›¸ä¼¼åº¦: {score:.4f})")
                st.markdown(f"- ğŸ¯ æ™¯ç‚¹ID: {info['æ™¯ç‚¹id']}")
                st.markdown(f"- ğŸ“Œ åœ°ç†ä½ç½®: {info['åœ°ç†ä½ç½®']}")
                st.markdown(f"- ğŸŒŸ ç®€ä»‹: {info['ç®€ä»‹'][:100]}...\n---")
        else:
            st.warning("æœªèƒ½åŒ¹é…åˆ°æ™¯ç‚¹ IDã€‚")
    else:
        st.info("è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ™¯ç‚¹ã€‚")

def page_content_attributes():
    st.header("ğŸ§© å†…å®¹è¿‡æ»¤ï¼šåŸºäºå±æ€§ç»„åˆæ¨è")
    selected = st.multiselect("é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªå±æ€§ï¼š", all_features)
    if selected:
        user_vec = np.zeros(len(all_features))
        for f in selected:
            if f in all_features:
                user_vec[all_features.index(f)] = 1
        sims = cosine_similarity([user_vec], feature_vectors)[0]
        idxs = sims.argsort()[::-1][:10]
        for i, j in enumerate(idxs):
            info = df_feat.iloc[j]
            score = sims[j]
            st.markdown(f"{i+1}. {info['æ™¯ç‚¹åç§°']} (åŒ¹é…åº¦: {score:.4f})")
            st.markdown(f"- ğŸ¯ æ™¯ç‚¹ID: {info['æ™¯ç‚¹id']}")
            st.markdown(f"- ğŸ“Œ åœ°ç†ä½ç½®: {info['åœ°ç†ä½ç½®']}")
            st.markdown(f"- ğŸŒŸ ç®€ä»‹: {info['ç®€ä»‹'][:100]}...\n---")
    else:
        st.info("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå±æ€§ã€‚")

# ------------------ ä¸»å‡½æ•° ------------------
def main():
    st.title("ğŸŒ„ ç»¼åˆæ™¯ç‚¹æ¨èç³»ç»Ÿ")
    tabs = st.tabs(["ğŸ“· å›¾ç‰‡è¯†åˆ«æ¨è", "ğŸ“ å•ä¸ªæ™¯ç‚¹æ¨è", "ğŸ§© å±æ€§ç»„åˆæ¨è"])
    with tabs[0]:
        page_select()
    with tabs[1]:
        page_content_single()
    with tabs[2]:
        page_content_attributes()

if __name__ == "__main__":
    main()
